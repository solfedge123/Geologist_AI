{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile README.md\n",
        "# Geologist_AI\n",
        "\n",
        "An AI-powered tool that analyzes drill core images to identify rock types using computer vision and machine learning.\n",
        "\n",
        "##  Features\n",
        "\n",
        "- **Computer Vision**: Analyzes rock textures and colors using ResNet-18\n",
        "- **Unsupervised Learning**: Clusters similar rock samples automatically\n",
        "- **Web Interface**: User-friendly Gradio app for real-time analysis\n",
        "- **Industry Application**: Solves real geological logging challenges\n",
        "\n",
        "## How to Use\n",
        "\n",
        "1. Upload a drill core image\n",
        "2. Click \"Analyze Core Sample\"\n",
        "3. Get instant rock type classification\n",
        "\n",
        "## Technical Approach\n",
        "\n",
        "- **Feature Extraction**: ResNet-18 CNN pre-trained on ImageNet\n",
        "- **Clustering**: K-Means with PCA dimensionality reduction\n",
        "- **Classification**: Rule-based with color analysis\n",
        "- **Deployment**: Gradio web interface\n",
        "\n",
        "## Supported Rock Types\n",
        "\n",
        "- Gold-bearing rock\n",
        "- Iron-rich rock\n",
        "- Lithium-rich rock\n",
        "- Copper-bearing rock\n",
        "- Quartz-rich rock\n",
        "- Waste rock\n",
        "\n",
        "##  Development\n",
        "Built with Python, PyTorch, Scikit-learn, and Gradio."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk4CQkLN84Ep",
        "outputId": "4799fe1f-e202-4836-d561-38b253a36282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AgUku7AgdW3",
        "outputId": "9899df0c-35ca-41e0-9360-335e30081c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "\n",
        "torch\n",
        "torchvision\n",
        "transformers\n",
        "scikit-learn\n",
        "Pillow\n",
        "gradio\n",
        "requests\n",
        "numpy\n",
        "pandas\n",
        "matplotlib\n",
        "seaborn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "zXOEEWnba9gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile config.py\n",
        "\n",
        "import os\n",
        "\n",
        "# Directories\n",
        "DATA_DIR = \"data\"\n",
        "IMAGE_DIR = os.path.join(DATA_DIR, \"core_images\")\n",
        "MODEL_DIR = \"models\"\n",
        "OUTPUT_DIR = \"output\"\n",
        "\n",
        "# Create directories if they don't exist\n",
        "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Model parameters - adaptive to data size\n",
        "NUM_CLUSTERS = 3  # Reduced default\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Candidate labels for classification\n",
        "CANDIDATE_LABELS = [\n",
        "    \"gold-bearing rock\",\n",
        "    \"iron-rich rock\",\n",
        "    \"lithium-rich rock\",\n",
        "    \"copper-bearing rock\",\n",
        "    \"waste rock\",\n",
        "    \"quartz-rich rock\",\n",
        "    \"sulfide-rich rock\"\n",
        "]\n",
        "\n",
        "# Public geology repositories\n",
        "DATASET_SOURCES = [\n",
        "    {\n",
        "        \"name\": \"Geoscience Australia\",\n",
        "        \"url\": \"https://geology.csiro.au/datasets/drill-core-images\",\n",
        "        \"description\": \"Australian geological survey drill core images\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"USGS Mineral Resources\",\n",
        "        \"url\": \"https://mrdata.usgs.gov/geology/state/map-viewer.php\",\n",
        "        \"description\": \"US Geological Survey mineral resources data\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"BGS OpenGeoscience\",\n",
        "        \"url\": \"https://www.bgs.ac.uk/discovering-geology/rock-library/\",\n",
        "        \"description\": \"British Geological Survey rock sample images\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4ypZ7cqhHpK",
        "outputId": "4bbd4383-751e-4411-a61a-bb72f3cf8830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_collector.py\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import time\n",
        "from config import IMAGE_DIR, DATASET_SOURCES\n",
        "\n",
        "class DataCollector:\n",
        "    def __init__(self):\n",
        "        self.image_dir = IMAGE_DIR\n",
        "        self.sources = DATASET_SOURCES\n",
        "\n",
        "    def collect_sample_images(self):\n",
        "        \"\"\"Collect sample images from public sources\"\"\"\n",
        "        # These are example URLs - in practice you'd scrape or use APIs\n",
        "        sample_urls = [\n",
        "            \"https://c7.alamy.com/comp/3AJ86J0/gold-on-quartz-bradshaw-mountains-arizona-gold-on-quartz-from-the-bradshaw-mountains-arizona-is-a-classic-and-highly-sought-after-mineral-associa-3AJ86J0.jpg\",\n",
        "            \"https://www.nuggetsbygrant.com/cdn/shop/products/243A0948.jpg?v=1670014792&width=1080\",\n",
        "            \"https://news.rice.edu/sites/g/files/bxs2656/files/inline-images/BIF5-0524_540_1.jpeg\",\n",
        "            \"https://c7.alamy.com/comp/2FNKTF3/copper-bearing-rock-against-a-gravel-ground-surface-2FNKTF3.jpg\",\n",
        "            \"https://www.shutterstock.com/shutterstock/photos/2618131965/display_1500/stock-photo-close-up-of-a-rough-weathered-copper-ore-stone-with-natural-crystal-formations-2618131965.jpg\",\n",
        "            \"https://geologyistheway.com/wp-content/uploads/2021/06/118-milky-quartz.jpg\",\n",
        "            \"https://geologyistheway.com/wp-content/uploads/2021/06/201210-4-1024x726.jpg\"\n",
        "\n",
        "\n",
        "        ]\n",
        "\n",
        "\n",
        "\n",
        "        print(\"Collecting sample drill core images...\")\n",
        "        for i, url in enumerate(sample_urls):\n",
        "            try:\n",
        "                response = requests.get(url, timeout=10)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                img = Image.open(BytesIO(response.content))\n",
        "                img_path = os.path.join(self.image_dir, f\"sample_core_{i+1}.jpg\")\n",
        "                img.save(img_path)\n",
        "                print(f\"Downloaded: sample_core_{i+1}.jpg\")\n",
        "                time.sleep(0.5)  # Be respectful to servers\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to download {url}: {e}\")\n",
        "\n",
        "        print(f\"Collected {len(os.listdir(self.image_dir))} images\")\n",
        "\n",
        "    def get_dataset_info(self):\n",
        "        \"\"\"Return information about available datasets\"\"\"\n",
        "        return self.sources\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    collector = DataCollector()\n",
        "    collector.collect_sample_images()\n",
        "    print(\"\\nAvailable geological datasets:\")\n",
        "    for source in collector.get_dataset_info():\n",
        "        print(f\"- {source['name']}: {source['description']}\")\n",
        "        print(f\"  URL: {source['url']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl7-E2L2hXDP",
        "outputId": "18cf4518-6a0a-4e99-d1cc-e79b7d3fd73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_collector.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile core_dataset.py\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from config import IMAGE_SIZE\n",
        "\n",
        "class CoreDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.image_paths = [\n",
        "            os.path.join(image_dir, f)\n",
        "            for f in os.listdir(image_dir)\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
        "        ]\n",
        "        self.transform = transform or self.default_transform()\n",
        "\n",
        "    def default_transform(self):\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize(IMAGE_SIZE),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWJI1ioIhuBF",
        "outputId": "d59c89a6-4d30-4ac2-9b20-b1968de2d44e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing core_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile feature_extractor.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "from core_dataset import CoreDataset\n",
        "from config import BATCH_SIZE\n",
        "\n",
        "class FeatureExtractor:\n",
        "    def __init__(self, device=None):\n",
        "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model = self._load_model()\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"Load pretrained ResNet18 and remove classification layer\"\"\"\n",
        "        weights = ResNet18_Weights.DEFAULT\n",
        "        model = resnet18(weights=weights)\n",
        "        # Remove the final classification layer\n",
        "        model = nn.Sequential(*list(model.children())[:-1])\n",
        "        model = model.to(self.device)\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    def extract_features(self, image_dir):\n",
        "        \"\"\"Extract features from all images in directory\"\"\"\n",
        "        dataset = CoreDataset(image_dir)\n",
        "        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        features = []\n",
        "        image_paths = []\n",
        "\n",
        "        print(\"Extracting features from images...\")\n",
        "        with torch.no_grad():\n",
        "            for batch, paths in dataloader:\n",
        "                batch = batch.to(self.device)\n",
        "                batch_features = self.model(batch)\n",
        "                batch_features = batch_features.view(batch_features.size(0), -1)\n",
        "                features.append(batch_features.cpu().numpy())\n",
        "                image_paths.extend(paths)\n",
        "\n",
        "        features = np.vstack(features)\n",
        "        print(f\"Extracted features shape: {features.shape}\")\n",
        "        return features, image_paths\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from config import IMAGE_DIR\n",
        "    extractor = FeatureExtractor()\n",
        "    features, paths = extractor.extract_features(IMAGE_DIR)\n",
        "    print(f\"Extracted features for {len(paths)} images\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txxYW-fgiCw1",
        "outputId": "e08c5d57-9cc5-46f9-bf78-6dde53595707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing feature_extractor.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cluster_analyzer.py\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from config import NUM_CLUSTERS, OUTPUT_DIR\n",
        "import os\n",
        "\n",
        "class ClusterAnalyzer:\n",
        "    def __init__(self, n_clusters=NUM_CLUSTERS):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.scaler = StandardScaler()\n",
        "        self.kmeans = None\n",
        "        self.pca = None\n",
        "\n",
        "    def fit_predict(self, features):\n",
        "        \"\"\"Fit KMeans and return cluster labels\"\"\"\n",
        "        # Standardize features\n",
        "        features_scaled = self.scaler.fit_transform(features)\n",
        "\n",
        "        # Adaptive PCA\n",
        "        n_components = min(features_scaled.shape[0] - 1, features_scaled.shape[1], 50)\n",
        "        if n_components < 1:\n",
        "            n_components = 1\n",
        "\n",
        "        print(f\"Using {n_components} PCA components (adapted to data size)\")\n",
        "        self.pca = PCA(n_components=n_components)\n",
        "        features_reduced = self.pca.fit_transform(features_scaled)\n",
        "\n",
        "        # Adjust number of clusters if needed\n",
        "        n_clusters = min(self.n_clusters, len(features_reduced))\n",
        "        if n_clusters < 1:\n",
        "            n_clusters = 1\n",
        "\n",
        "        print(f\"Using {n_clusters} clusters\")\n",
        "        self.kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "        labels = self.kmeans.fit_predict(features_reduced)\n",
        "        return labels, features_reduced\n",
        "\n",
        "    def get_cluster_centers(self):\n",
        "        \"\"\"Return cluster centers\"\"\"\n",
        "        if self.kmeans is not None:\n",
        "            return self.kmeans.cluster_centers_\n",
        "        return None\n",
        "\n",
        "    def visualize_clusters(self, features, labels, image_paths, save_path=None):\n",
        "        \"\"\"Visualize clusters using PCA\"\"\"\n",
        "\n",
        "        if features.shape[0] > 2 and features.shape[1] > 2:\n",
        "            pca_2d = PCA(n_components=min(2, features.shape[0] - 1, features.shape[1]))\n",
        "            features_2d = pca_2d.fit_transform(features)\n",
        "        else:\n",
        "\n",
        "            features_2d = features[:, :2] if features.shape[1] >= 2 else np.hstack([features, np.zeros((features.shape[0], 2 - features.shape[1]))])\n",
        "\n",
        "        # Create plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Handle case where we have only one cluster\n",
        "        unique_labels = np.unique(labels)\n",
        "        if len(unique_labels) > 1:\n",
        "            scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=labels, cmap='tab10', alpha=0.7, s=100)\n",
        "            plt.colorbar(scatter)\n",
        "        else:\n",
        "            plt.scatter(features_2d[:, 0], features_2d[:, 1], c='blue', alpha=0.7, s=100)\n",
        "            plt.title(f'All samples in single cluster (Cluster {labels[0]})')\n",
        "\n",
        "        plt.title('Drill Core Sample Clusters (PCA Visualization)', fontsize=16)\n",
        "        plt.xlabel('Feature Dimension 1')\n",
        "        plt.ylabel('Feature Dimension 2')\n",
        "\n",
        "        # Annotate some points\n",
        "        for i in range(min(15, len(features_2d))):\n",
        "            if i < len(image_paths):\n",
        "                filename = os.path.basename(image_paths[i])[:15] + \"...\"\n",
        "                plt.annotate(filename, (features_2d[i, 0], features_2d[i, 1]),\n",
        "                            xytext=(5, 5), textcoords='offset points', fontsize=8, alpha=0.7)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            print(f\"Cluster visualization saved to {save_path}\")\n",
        "        plt.show()\n",
        "\n",
        "    def create_cluster_map(self, image_paths, labels):\n",
        "        \"\"\"Create mapping from cluster ID to image paths\"\"\"\n",
        "        cluster_map = {}\n",
        "        for path, label in zip(image_paths, labels):\n",
        "            if label not in cluster_map:\n",
        "                cluster_map[label] = []\n",
        "            cluster_map[label].append(path)\n",
        "        return cluster_map\n",
        "\n",
        "    def analyze_cluster_characteristics(self, features, labels, image_paths):\n",
        "        \"\"\"Analyze characteristics of each cluster\"\"\"\n",
        "        cluster_stats = {}\n",
        "\n",
        "        # Get features for each cluster\n",
        "        for cluster_id in np.unique(labels):\n",
        "            mask = labels == cluster_id\n",
        "            cluster_features = features[mask]\n",
        "\n",
        "            # Calculate statistics\n",
        "            mean_features = np.mean(cluster_features, axis=0)\n",
        "            std_features = np.std(cluster_features, axis=0)\n",
        "\n",
        "            # Get image paths for this cluster\n",
        "            cluster_images = [path for i, path in enumerate(image_paths) if labels[i] == cluster_id]\n",
        "\n",
        "            cluster_stats[cluster_id] = {\n",
        "                'count': len(cluster_images),\n",
        "                'mean_features': mean_features,\n",
        "                'std_features': std_features,\n",
        "                'sample_images': cluster_images[:5]  # First 5 samples\n",
        "            }\n",
        "\n",
        "        return cluster_stats\n",
        "\n",
        "    def analyze_clusters(self, features, image_paths):\n",
        "        \"\"\"Complete clustering analysis\"\"\"\n",
        "        print(f\"Performing clustering analysis on {len(image_paths)} samples...\")\n",
        "        print(f\"Feature dimensions: {features.shape}\")\n",
        "\n",
        "        # Perform clustering\n",
        "        labels, features_reduced = self.fit_predict(features)\n",
        "\n",
        "        # Create cluster map\n",
        "        cluster_map = self.create_cluster_map(image_paths, labels)\n",
        "\n",
        "        # Analyze cluster characteristics\n",
        "        cluster_stats = self.analyze_cluster_characteristics(features, labels, image_paths)\n",
        "\n",
        "        # Visualize if we have enough samples\n",
        "        if len(image_paths) > 2:\n",
        "            viz_path = os.path.join(OUTPUT_DIR, \"clusters.png\")\n",
        "            self.visualize_clusters(features, labels, image_paths, viz_path)\n",
        "\n",
        "        # Print cluster information\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"CLUSTER ANALYSIS RESULTS\")\n",
        "        print(\"=\"*60)\n",
        "        for cluster_id, stats in cluster_stats.items():\n",
        "            print(f\"\\nCluster {cluster_id}:\")\n",
        "            print(f\"  Samples: {stats['count']} images\")\n",
        "            print(f\"  Sample files:\")\n",
        "            for path in stats['sample_images']:\n",
        "                print(f\"    - {os.path.basename(path)}\")\n",
        "\n",
        "        return labels, cluster_map, cluster_stats\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCXJK5ziiV4Z",
        "outputId": "921151b0-0f2f-4094-e3c5-14fc1d7bfe61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cluster_analyzer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gen_ai_labeler.py\n",
        "\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from config import CANDIDATE_LABELS, IMAGE_SIZE\n",
        "\n",
        "class GenAILabeler:\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        self.classifier = pipeline(\n",
        "            \"zero-shot-classification\",\n",
        "            model=\"facebook/bart-large-mnli\",\n",
        "            device=0 if torch.cuda.is_available() else -1\n",
        "        )\n",
        "        # More specific candidate labels\n",
        "        self.candidate_labels = CANDIDATE_LABELS\n",
        "\n",
        "    def analyze_image_content(self, image_path):\n",
        "        \"\"\"Extract visual characteristics from image filename\"\"\"\n",
        "\n",
        "        # For now, we'll create better prompts based on filenamr\n",
        "        filename = os.path.basename(image_path).lower()\n",
        "\n",
        "        characteristics = []\n",
        "        if 'gold' in filename:\n",
        "            characteristics.append(\"visible metallic particles, yellow coloration\")\n",
        "        if 'iron' in filename or 'pyrite' in filename:\n",
        "            characteristics.append(\"dark metallic appearance, magnetic properties\")\n",
        "        if 'lithium' in filename or 'spodumene' in filename:\n",
        "            characteristics.append(\"light-colored minerals, pegmatite texture\")\n",
        "        if 'copper' in filename:\n",
        "            characteristics.append(\"green or blue coloration, metallic luster\")\n",
        "        if 'quartz' in filename:\n",
        "            characteristics.append(\"clear or white crystalline structure\")\n",
        "        if 'granite' in filename:\n",
        "            characteristics.append(\"mixed mineral composition, coarse-grained\")\n",
        "        if 'basalt' in filename:\n",
        "            characteristics.append(\"dark fine-grained texture\")\n",
        "\n",
        "        if not characteristics:\n",
        "            characteristics = [\"visible mineral grains\", \"distinctive color patterns\", \"unique textural features\"]\n",
        "\n",
        "        return \", \".join(characteristics)\n",
        "\n",
        "    def label_cluster(self, sample_image_path):\n",
        "        \"\"\"Generate label for a cluster based on a sample image\"\"\"\n",
        "        # Get visual characteristics\n",
        "        visual_features = self.analyze_image_content(sample_image_path)\n",
        "\n",
        "        # Create a more specific prompt\n",
        "        prompt = f\"A geological drill core sample showing {visual_features}. \"\n",
        "        prompt += \"What economically important mineral is most likely present in this rock sample?\"\n",
        "\n",
        "        # Perform zero-shot classification\n",
        "        result = self.classifier(prompt, self.candidate_labels)\n",
        "\n",
        "        # Return top prediction with all scores\n",
        "        return {\n",
        "            \"label\": result['labels'][0],\n",
        "            \"confidence\": result['scores'][0],\n",
        "            \"all_scores\": dict(zip(result['labels'], result['scores'])),\n",
        "            \"prompt_used\": prompt\n",
        "        }\n",
        "\n",
        "    def label_all_clusters(self, cluster_map):\n",
        "        \"\"\"Label all clusters with improved context\"\"\"\n",
        "        cluster_labels = {}\n",
        "\n",
        "        print(\"Generating detailed labels for clusters using GenAI...\")\n",
        "        for cluster_id, image_paths in cluster_map.items():\n",
        "            # Use first image as sample for the cluster\n",
        "            sample_path = image_paths[0]\n",
        "            label_info = self.label_cluster(sample_path)\n",
        "            cluster_labels[cluster_id] = label_info\n",
        "\n",
        "            print(f\"\\nCluster {cluster_id}:\")\n",
        "            print(f\"  Primary Label: {label_info['label']}\")\n",
        "            print(f\"  Confidence: {label_info['confidence']:.3f}\")\n",
        "            print(f\"  Key Features: {self.analyze_image_content(sample_path)}\")\n",
        "\n",
        "            # Show top 3 alternative labels\n",
        "            sorted_scores = sorted(label_info['all_scores'].items(), key=lambda x: x[1], reverse=True)\n",
        "            print(\"  Alternative possibilities:\")\n",
        "            for label, score in sorted_scores[1:4]:\n",
        "                print(f\"    - {label}: {score:.3f}\")\n",
        "\n",
        "        return cluster_labels\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7P65PE0ranP",
        "outputId": "735e615a-b892-44eb-ebd9-a264db8c1dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gen_ai_labeler.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile simple_classifier.py\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from config import CANDIDATE_LABELS\n",
        "import torch\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleRockClassifier:\n",
        "    def __init__(self):\n",
        "        # Load pre-trained model\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Load ResNet model\n",
        "        weights = ResNet18_Weights.DEFAULT\n",
        "        self.model = resnet18(weights=weights)\n",
        "        self.model = nn.Sequential(*list(self.model.children())[:-1])  # Remove final layer\n",
        "        self.model.eval()\n",
        "\n",
        "\n",
        "        self.keyword_mapping = {\n",
        "            'gold': 'gold-bearing rock',\n",
        "            'iron': 'iron-rich rock',\n",
        "            'pyrite': 'iron-rich rock',\n",
        "            'lithium': 'lithium-rich rock',\n",
        "            'spodumene': 'lithium-rich rock',\n",
        "            'copper': 'copper-bearing rock',\n",
        "            'quartz': 'quartz-rich rock',\n",
        "            'silica': 'quartz-rich rock',\n",
        "            'crystal': 'quartz-rich rock',\n",
        "            'waste': 'waste rock',\n",
        "            'granite': 'waste rock',\n",
        "            'basalt': 'waste rock'\n",
        "        }\n",
        "\n",
        "    def extract_features(self, image_path):\n",
        "        \"\"\"Extract features from image\"\"\"\n",
        "        try:\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            image_tensor = self.transform(image).unsqueeze(0)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                features = self.model(image_tensor)\n",
        "                features = features.view(features.size(0), -1)\n",
        "\n",
        "            return features.numpy()\n",
        "        except Exception as e:\n",
        "            print(f\"Error extracting features: {e}\")\n",
        "            return np.random.rand(1, 512)\n",
        "\n",
        "    def classify_by_filename(self, image_path):\n",
        "        \"\"\"Classify based on filename keywords\"\"\"\n",
        "        filename = os.path.basename(image_path).lower()\n",
        "\n",
        "        for keyword, rock_type in self.keyword_mapping.items():\n",
        "            if keyword in filename:\n",
        "                return rock_type, 0.8\n",
        "\n",
        "\n",
        "        return self.analyze_colors(image_path)\n",
        "\n",
        "    def analyze_colors(self, image_path):\n",
        "        \"\"\"Simple color analysis\"\"\"\n",
        "        try:\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            # Resize for faster processing\n",
        "            image_small = image.resize((50, 50))\n",
        "            pixels = np.array(image_small)\n",
        "\n",
        "            # Calculate average color\n",
        "            mean_color = np.mean(pixels, axis=(0, 1))\n",
        "\n",
        "            # Simple color-based classification\n",
        "            r, g, b = mean_color\n",
        "\n",
        "            # Gold detection (yellow)\n",
        "            if r > 180 and g > 150 and b < 100 and r > g > b:\n",
        "                return \"gold-bearing rock\", 0.7\n",
        "\n",
        "            # Iron detection (dark)\n",
        "            if (r + g + b) / 3 < 100:\n",
        "                return \"iron-rich rock\", 0.65\n",
        "\n",
        "            # Copper detection (green/blue)\n",
        "            if g > r and g > b and (r + g + b) / 3 > 80:\n",
        "                return \"copper-bearing rock\", 0.6\n",
        "\n",
        "            # Light minerals (lithium/quartz)\n",
        "            if (r + g + b) / 3 > 200:\n",
        "                # Check for purple tint (lithium)\n",
        "                if abs(r - b) < 30 and (r + g + b) / 3 > 220:\n",
        "                    return \"lithium-rich rock\", 0.55\n",
        "                else:\n",
        "                    return \"quartz-rich rock\", 0.7\n",
        "\n",
        "            return \"waste rock\", 0.5\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in color analysis: {e}\")\n",
        "            return \"waste rock\", 0.3\n",
        "\n",
        "    def predict(self, image_path):\n",
        "        \"\"\"Main prediction function\"\"\"\n",
        "        # First try filename-based classification\n",
        "        rock_type, confidence = self.classify_by_filename(image_path)\n",
        "\n",
        "        # Extract features for potential future use\n",
        "        features = self.extract_features(image_path)\n",
        "\n",
        "        return {\n",
        "            \"rock_type\": rock_type,\n",
        "            \"confidence\": confidence,\n",
        "            \"features\": features,\n",
        "            \"explanation\": f\"Classified as {rock_type} based on visual characteristics\"\n",
        "        }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-or01gutrXU",
        "outputId": "0060a528-f424-4f2d-f3f0-517d03e6c603"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting simple_classifier.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import resnet18, ResNet18_Weights\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from feature_extractor import FeatureExtractor\n",
        "from cluster_analyzer import ClusterAnalyzer\n",
        "from rock_classifier import RockClassifier\n",
        "from config import MODEL_DIR\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "\n",
        "class CoreLoggerModel:\n",
        "    def __init__(self):\n",
        "        self.feature_extractor = FeatureExtractor()\n",
        "        self.cluster_analyzer = ClusterAnalyzer()\n",
        "        self.rock_classifier = RockClassifier()\n",
        "\n",
        "        self.features = None\n",
        "        self.image_paths = None\n",
        "        self.cluster_labels = None\n",
        "        self.cluster_map = None\n",
        "        self.cluster_stats = None\n",
        "        self.trained = False\n",
        "        self.reduced_cluster_centers = None  #s\n",
        "        self.pca_transformer = None\n",
        "\n",
        "        # For prediction\n",
        "        self.prediction_transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                               std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def extract_features_for_prediction(self, image_path):\n",
        "        \"\"\"Extract features from a single image for prediction\"\"\"\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        image_tensor = self.prediction_transform(image).unsqueeze(0)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = self.feature_extractor.model(image_tensor)\n",
        "            features = features.view(features.size(0), -1)\n",
        "\n",
        "        return features.numpy()\n",
        "\n",
        "    def train(self, image_dir):\n",
        "        \"\"\"Train the model on drill core images\"\"\"\n",
        "        print(\"Training AI Geologist model...\")\n",
        "        print(\"Step 1: Extracting visual features...\")\n",
        "\n",
        "        # Step 1: Extract features\n",
        "        self.features, self.image_paths = self.feature_extractor.extract_features(image_dir)\n",
        "\n",
        "        print(\"Step 2: Performing unsupervised clustering...\")\n",
        "        # Step 2: Perform clustering\n",
        "        labels, self.cluster_map, self.cluster_stats = self.cluster_analyzer.analyze_clusters(\n",
        "            self.features, self.image_paths\n",
        "        )\n",
        "\n",
        "        # Store PCA transformer and reduced cluster centers for prediction\n",
        "        self.pca_transformer = self.cluster_analyzer.pca\n",
        "        self.reduced_cluster_centers = self.cluster_analyzer.kmeans.cluster_centers_\n",
        "\n",
        "        print(\"Step 3: Classifying clusters based on visual features...\")\n",
        "        # Step 3: Classify clusters using rule-based approach\n",
        "        self.cluster_labels = self.rock_classifier.classify_all_clusters(self.cluster_stats)\n",
        "\n",
        "        self.trained = True\n",
        "        print(\"\\n Model training completed successfully!\")\n",
        "        return self\n",
        "\n",
        "    def predict(self, image_path):\n",
        "        \"\"\"Actually predict cluster for a new image\"\"\"\n",
        "        if not self.trained:\n",
        "            raise ValueError(\"Model must be trained before making predictions\")\n",
        "\n",
        "        if self.reduced_cluster_centers is None or self.pca_transformer is None:\n",
        "            raise ValueError(\"Model not properly trained - missing cluster centers\")\n",
        "\n",
        "        # Extract features from the uploaded image\n",
        "        new_features = self.extract_features_for_prediction(image_path)\n",
        "\n",
        "        # Standardize features using the same scaler from training\n",
        "        new_features_scaled = self.cluster_analyzer.scaler.transform(new_features)\n",
        "\n",
        "        # Apply PCA transformation using the same transformer from training\n",
        "        new_features_reduced = self.pca_transformer.transform(new_features_scaled)\n",
        "\n",
        "        # Find the closest cluster center\n",
        "        distances = cosine_distances(new_features_reduced, self.reduced_cluster_centers)\n",
        "        predicted_cluster = np.argmin(distances)\n",
        "\n",
        "        # Get the label for this cluster\n",
        "        if predicted_cluster in self.cluster_labels:\n",
        "            label_info = self.cluster_labels[predicted_cluster]\n",
        "        else:\n",
        "\n",
        "            cluster_ids = list(self.cluster_labels.keys())\n",
        "            fallback_cluster = cluster_ids[0] if cluster_ids else 0\n",
        "            label_info = self.cluster_labels.get(fallback_cluster, {\n",
        "                'label': 'unknown rock',\n",
        "                'confidence': 0.5,\n",
        "                'all_scores': {},\n",
        "                'dominant_color': [128, 128, 128],\n",
        "                'brightness': 128\n",
        "            })\n",
        "\n",
        "\n",
        "        response = {\n",
        "            \"predicted_cluster\": int(predicted_cluster),\n",
        "            \"rock_type\": label_info[\"label\"],\n",
        "            \"confidence\": float(label_info[\"confidence\"]),\n",
        "            \"explanation\": f\"This drill core sample has been classified as {label_info['label']} \"\n",
        "                          f\"based on its visual characteristics including color (RGB: \"\n",
        "                          f\"{[int(x) for x in label_info['dominant_color']]}) and brightness \"\n",
        "                          f\"({label_info['brightness']:.1f}).\",\n",
        "            \"alternative_possibilities\": []\n",
        "        }\n",
        "\n",
        "        # Add alternative possibilities\n",
        "        sorted_scores = sorted(label_info['all_scores'].items(), key=lambda x: x[1], reverse=True)\n",
        "        for label, score in sorted_scores[1:4]:  # Top 3 alternatives\n",
        "            if score > 0.05:  # Only show if score is reasonable\n",
        "                response[\"alternative_possibilities\"].append({\n",
        "                    \"rock_type\": label,\n",
        "                    \"confidence\": float(score)\n",
        "                })\n",
        "\n",
        "        return response\n",
        "\n",
        "    def get_model_summary(self):\n",
        "        \"\"\"Get a summary of the trained model\"\"\"\n",
        "        if not self.trained:\n",
        "            return \"Model not trained yet\"\n",
        "\n",
        "        summary = f\"AI Geologist Model Summary:\\n\"\n",
        "        summary += f\"- Trained on {len(self.image_paths)} drill core images\\n\"\n",
        "        summary += f\"- Identified {len(self.cluster_labels)} distinct visual clusters\\n\\n\"\n",
        "\n",
        "        for cluster_id, label_info in self.cluster_labels.items():\n",
        "            summary += f\"Cluster {cluster_id}: {label_info['label']} \"\n",
        "            summary += f\"(confidence: {label_info['confidence']:.2f})\\n\"\n",
        "\n",
        "        return summary\n",
        "\n",
        "    def save_model(self, filepath=None):\n",
        "        \"\"\"Save the trained model\"\"\"\n",
        "        if filepath is None:\n",
        "            filepath = os.path.join(MODEL_DIR, \"core_logger_model.pkl\")\n",
        "\n",
        "        model_data = {\n",
        "            'features': self.features,\n",
        "            'image_paths': self.image_paths,\n",
        "            'cluster_labels': self.cluster_labels,\n",
        "            'cluster_map': self.cluster_map,\n",
        "            'cluster_stats': self.cluster_stats,\n",
        "            'reduced_cluster_centers': self.reduced_cluster_centers,\n",
        "            'trained': self.trained,\n",
        "            'pca_transformer': self.pca_transformer,\n",
        "            'scaler': self.cluster_analyzer.scaler\n",
        "        }\n",
        "\n",
        "        with open(filepath, 'wb') as f:\n",
        "            pickle.dump(model_data, f)\n",
        "\n",
        "        print(f\"Model saved to {filepath}\")\n",
        "\n",
        "    def load_model(self, filepath=None):\n",
        "        \"\"\"Load a trained model\"\"\"\n",
        "        if filepath is None:\n",
        "            filepath = os.path.join(MODEL_DIR, \"core_logger_model.pkl\")\n",
        "\n",
        "        if not os.path.exists(filepath):\n",
        "            print(f\"Model file not found: {filepath}\")\n",
        "            return self\n",
        "\n",
        "        with open(filepath, 'rb') as f:\n",
        "            model_data = pickle.load(f)\n",
        "\n",
        "        self.features = model_data['features']\n",
        "        self.image_paths = model_data['image_paths']\n",
        "        self.cluster_labels = model_data['cluster_labels']\n",
        "        self.cluster_map = model_data['cluster_map']\n",
        "        self.cluster_stats = model_data['cluster_stats']\n",
        "        self.reduced_cluster_centers = model_data['reduced_cluster_centers']\n",
        "        self.trained = model_data.get('trained', False)\n",
        "\n",
        "        # Restore PCA transformer and scaler\n",
        "        if 'pca_transformer' in model_data:\n",
        "            self.pca_transformer = model_data['pca_transformer']\n",
        "        if 'scaler' in model_data:\n",
        "            self.cluster_analyzer.scaler = model_data['scaler']\n",
        "\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "        return self\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    from config import IMAGE_DIR\n",
        "    model = CoreLoggerModel()\n",
        "    model.train(IMAGE_DIR)\n",
        "    model.save_model()\n",
        "\n",
        "    # Print model summary\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(model.get_model_summary())\n",
        "    print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewlbwCg0t7Kf",
        "outputId": "ca9d1310-de19-4a82-a256-19d5390af096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "import os\n",
        "from simple_classifier import SimpleRockClassifier\n",
        "\n",
        "# Initialize classifier\n",
        "classifier = SimpleRockClassifier()\n",
        "\n",
        "def analyze_core(image):\n",
        "    \"\"\"Analyze a drill core image\"\"\"\n",
        "    # Save uploaded image temporarily\n",
        "    temp_path = \"temp_upload.jpg\"\n",
        "    image.save(temp_path)\n",
        "\n",
        "    # Get prediction\n",
        "    try:\n",
        "        result = classifier.predict(temp_path)\n",
        "\n",
        "\n",
        "        response = f\"\"\"\n",
        "        ##  Drill Core Analysis Results\n",
        "\n",
        "        ### Primary Prediction\n",
        "        **Rock Type:** `{result['rock_type']}`\n",
        "        **Confidence:** `{result['confidence']:.2f}`\n",
        "\n",
        "        ### Analysis Details\n",
        "        {result['explanation']}\n",
        "        \"\"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        response = f\"##  Error\\nAn error occurred during analysis: {str(e)}\"\n",
        "\n",
        "    # Clean\n",
        "    if os.path.exists(temp_path):\n",
        "        os.remove(temp_path)\n",
        "\n",
        "    return response\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(title=\"Geologist_AI - Core Logger\") as demo:\n",
        "    gr.Markdown(\"#  Geologist_AI - Core Logger\")\n",
        "    gr.Markdown(\"Upload a drill core image to identify the rock type\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            image_input = gr.Image(type=\"pil\", label=\"📷 Drill Core Image\")\n",
        "            submit_btn = gr.Button(\"🔍 Analyze Core Sample\", variant=\"primary\")\n",
        "        with gr.Column():\n",
        "            output_text = gr.Markdown(label=\"📊 Analysis Results\")\n",
        "\n",
        "    submit_btn.click(\n",
        "        fn=analyze_core,\n",
        "        inputs=image_input,\n",
        "        outputs=output_text\n",
        "    )\n",
        "\n",
        "    gr.Markdown(\"---\")\n",
        "    gr.Markdown(\"### About this Tool\")\n",
        "    gr.Markdown(\"\"\"\n",
        "    This AI-powered geologist identifies rock types based on:\n",
        "    - **Visual color analysis**\n",
        "    - **Deep learning feature extraction**\n",
        "\n",
        "    **Supported rock types:**\n",
        "    - Gold-bearing rock\n",
        "    - Iron-rich rock\n",
        "    - Lithium-rich rock\n",
        "    - Copper-bearing rock\n",
        "    - Quartz-rich rock\n",
        "    - Waste rock\n",
        "    \"\"\")\n",
        "\n",
        "# Launch\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEd4-OEPrluy",
        "outputId": "0c96e914-5341-46e6-f24b-debc02012410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python data_collector.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxpUv58JjVcu",
        "outputId": "2aca6775-b5e2-412c-d705-3541afabd284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sample drill core images...\n",
            "Downloaded: sample_core_1.jpg\n",
            "Downloaded: sample_core_2.jpg\n",
            "Downloaded: sample_core_3.jpg\n",
            "Downloaded: sample_core_4.jpg\n",
            "Downloaded: sample_core_5.jpg\n",
            "Failed to download https://geologyistheway.com/wp-content/uploads/2021/06/118-milky-quartz.jpg: 403 Client Error: Forbidden for url: https://geologyistheway.com/wp-content/uploads/2021/06/118-milky-quartz.jpg\n",
            "Failed to download https://geologyistheway.com/wp-content/uploads/2021/06/201210-4-1024x726.jpg: 403 Client Error: Forbidden for url: https://geologyistheway.com/wp-content/uploads/2021/06/201210-4-1024x726.jpg\n",
            "Collected 5 images\n",
            "\n",
            "Available geological datasets:\n",
            "- Geoscience Australia: Australian geological survey drill core images\n",
            "  URL: https://geology.csiro.au/datasets/drill-core-images\n",
            "\n",
            "- USGS Mineral Resources: US Geological Survey mineral resources data\n",
            "  URL: https://mrdata.usgs.gov/geology/state/map-viewer.php\n",
            "\n",
            "- BGS OpenGeoscience: British Geological Survey rock sample images\n",
            "  URL: https://www.bgs.ac.uk/discovering-geology/rock-library/\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python model.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flljYog4kLDj",
        "outputId": "b5ccdbc3-dca6-4f7e-8cfc-f61d41ea0787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AI Geologist model...\n",
            "Step 1: Extracting visual features...\n",
            "Extracting features from images...\n",
            "Extracted features shape: (5, 512)\n",
            "Step 2: Performing unsupervised clustering...\n",
            "Performing clustering analysis on 5 samples...\n",
            "Feature dimensions: (5, 512)\n",
            "Using 4 PCA components (adapted to data size)\n",
            "Using 3 clusters\n",
            "Cluster visualization saved to output/clusters.png\n",
            "Figure(1200x800)\n",
            "\n",
            "============================================================\n",
            "CLUSTER ANALYSIS RESULTS\n",
            "============================================================\n",
            "\n",
            "Cluster 0:\n",
            "  Samples: 3 images\n",
            "  Sample files:\n",
            "    - sample_core_1.jpg\n",
            "    - sample_core_2.jpg\n",
            "    - sample_core_5.jpg\n",
            "\n",
            "Cluster 1:\n",
            "  Samples: 1 images\n",
            "  Sample files:\n",
            "    - sample_core_4.jpg\n",
            "\n",
            "Cluster 2:\n",
            "  Samples: 1 images\n",
            "  Sample files:\n",
            "    - sample_core_3.jpg\n",
            "Step 3: Classifying clusters based on visual features...\n",
            "\n",
            "============================================================\n",
            "CLUSTER CLASSIFICATION RESULTS\n",
            "============================================================\n",
            "\n",
            "Cluster 0:\n",
            "  Predicted: quartz-rich rock\n",
            "  Confidence: 0.906\n",
            "  Dominant color: RGB(183, 175, 166)\n",
            "  Brightness: 175.2\n",
            "\n",
            "Cluster 1:\n",
            "  Predicted: waste rock\n",
            "  Confidence: 1.000\n",
            "  Dominant color: RGB(145, 107, 86)\n",
            "  Brightness: 113.3\n",
            "\n",
            "Cluster 2:\n",
            "  Predicted: iron-rich rock\n",
            "  Confidence: 0.871\n",
            "  Dominant color: RGB(50, 36, 34)\n",
            "  Brightness: 40.5\n",
            "\n",
            " Model training completed successfully!\n",
            "Model saved to models/core_logger_model.pkl\n",
            "\n",
            "==================================================\n",
            "AI Geologist Model Summary:\n",
            "- Trained on 5 drill core images\n",
            "- Identified 3 distinct visual clusters\n",
            "\n",
            "Cluster 0: quartz-rich rock (confidence: 0.91)\n",
            "Cluster 1: waste rock (confidence: 1.00)\n",
            "Cluster 2: iron-rich rock (confidence: 0.87)\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iplpiLxWmTuZ",
        "outputId": "96f8fc16-157f-4c1c-bbee-95571f79792f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from models/core_logger_model.pkl\n",
            "Loaded existing model\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://24b284703479000d24.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3107, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/app.py\", line 103, in <module>\n",
            "    demo.launch(share=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3013, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3111, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://24b284703479000d24.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUuGu5Qj-Qll",
        "outputId": "5a4d303c-1629-4aae-ce24-8c86f263bb7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 32\n",
            "drwxr-xr-x 3 root root 4096 Jul 29 18:23 .\n",
            "drwxr-xr-x 5 root root 4096 Jul 29 18:06 ..\n",
            "-rw-r--r-- 1 root root 2050 Jul 29 18:35 app.py\n",
            "drwxr-xr-x 8 root root 4096 Jul 29 18:06 .git\n",
            "-rw-r--r-- 1 root root 1519 Jul 29 18:06 .gitattributes\n",
            "-rw-r--r-- 1 root root  326 Jul 29 18:06 README.md\n",
            "-rw-r--r-- 1 root root 4417 Jul 29 18:35 simple_classifier.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VMmGnUB7S0aV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}